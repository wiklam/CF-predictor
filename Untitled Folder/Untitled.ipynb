{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from database import Database, LoadDatabase\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = nn.Linear(6, 10)\n",
    "        self.layer2 = nn.Linear(10,3)\n",
    "        self.layer3 = nn.Linear(3,1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.tanh(self.layer1(x))\n",
    "        x = F.tanh(self.layer2(x))\n",
    "        x = F.sigmoid(self.layer3(x))\n",
    "        return x\n",
    "\n",
    "def save_nn():\n",
    "    torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB = LoadDatabase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, db):\n",
    "        self.standings = db.standings\n",
    "        self.contestIDs = list(db.contests.index)\n",
    "        self.contestSTs = list(db.contests.startTime)\n",
    "        self.contestIDs.reverse()\n",
    "        self.contestSTs.reverse()\n",
    "        self.startRating = 1500\n",
    "    \n",
    "    def genDataset(self):\n",
    "        userHistory = {}\n",
    "        dataset = []\n",
    "        counter = 0\n",
    "        for contest, sTime in zip(self.contestIDs, self.contestSTs):\n",
    "            if counter > 10:\n",
    "                break\n",
    "            counter += 1\n",
    "            print('Starting contest ', contest)\n",
    "            print('contest size:', len(self.standings[contest]))\n",
    "            dataset = dataset + self.SingleContestGen(contest, sTime, userHistory)\n",
    "            userHistory = self.UpdateUserHistory(contest, sTime, userHistory)\n",
    "            print('Contest ', contest, ' is done')\n",
    "        return dataset\n",
    "    \n",
    "    def SingleContestGen(self, contest, sTime, userHistory):\n",
    "        dataset = []\n",
    "        for name, data in self.standings[contest].iterrows():\n",
    "            for otherName, otherData in self.standings[contest].iterrows():\n",
    "                if name != otherName:\n",
    "                    stuff = np.array([\n",
    "                        data['oldRating'],\n",
    "                        otherData['oldRating'],\n",
    "                        self.GetInactiveTime(name, sTime, userHistory),\n",
    "                        self.GetInactiveTime(otherName, sTime, userHistory),\n",
    "                        0.,\n",
    "                        0.,\n",
    "                        self.IsFirstHigher(data, otherData)\n",
    "                    ])\n",
    "                    dataset.append(stuff)\n",
    "        return dataset\n",
    "    \n",
    "    def GetInactiveTime(self, name, sTime, userHistory):\n",
    "        if name not in userHistory:\n",
    "            return 0.\n",
    "        prevContest = userHistory[name][-1]\n",
    "        return sTime - prevContest['startTime']\n",
    "                                    \n",
    "    \n",
    "    def UpdateUserHistory(self, contest, sTime, userHistory):\n",
    "        for name, data in self.standings[contest].iterrows():\n",
    "            if name not in userHistory:\n",
    "                userHistory[name] = [{'newRating': self.startRating}]\n",
    "            userHistory[name].append({'newRating': data['newRating'], 'startTime': sTime})\n",
    "        return userHistory\n",
    "    \n",
    "    def IsFirstHigher(self, data, otherData):\n",
    "        if data['rank'] < otherData['rank']:\n",
    "            return 1\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting contest  26\n",
      "contest size: 509\n",
      "Contest  26  is done\n",
      "Starting contest  27\n",
      "contest size: 389\n",
      "Contest  27  is done\n",
      "Starting contest  28\n",
      "contest size: 379\n",
      "Contest  28  is done\n",
      "Starting contest  29\n",
      "contest size: 355\n",
      "Contest  29  is done\n",
      "Starting contest  30\n",
      "contest size: 570\n",
      "Contest  30  is done\n",
      "Starting contest  31\n",
      "contest size: 401\n",
      "Contest  31  is done\n",
      "Starting contest  32\n",
      "contest size: 240\n",
      "Contest  32  is done\n",
      "Starting contest  33\n",
      "contest size: 614\n",
      "Contest  33  is done\n",
      "Starting contest  34\n",
      "contest size: 410\n",
      "Contest  34  is done\n",
      "Starting contest  35\n",
      "contest size: 249\n",
      "Contest  35  is done\n",
      "Starting contest  36\n",
      "contest size: 395\n",
      "Contest  36  is done\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset.genDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nn-dataset.pickle', 'wb') as file:\n",
    "    pickle.dump(dataset, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-04f088450e31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array_repr_implementation\u001b[0;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1402\u001b[0;31m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0m\u001b[1;32m   1403\u001b[0m                            ', ', prefix, suffix=suffix)\n\u001b[1;32m   1404\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, **kwarg)\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mnext_line_prefix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m     lst = _formatArray(a, format_function, options['linewidth'],\n\u001b[0m\u001b[1;32m    518\u001b[0m                        \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edgeitems'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                        summary_insert, options['legacy'])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, line_width, next_line_prefix, separator, edge_items, summary_insert, legacy)\u001b[0m\n\u001b[1;32m    836\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;31m# invoke the recursive part with an initial index and prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m         return recurser(index=(),\n\u001b[0m\u001b[1;32m    839\u001b[0m                         \u001b[0mhanging_indent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m                         curr_width=line_width)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrailing_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_hanging_indent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m                 s, line = _extendLine(\n\u001b[1;32m    796\u001b[0m                     s, line, word, elem_width, hanging_indent, legacy)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mrecurser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhanging_indent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         \"\"\"\n\u001b[1;32m    740\u001b[0m         \u001b[0mBy\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mlocal\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0mdon\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0mt\u001b[0m \u001b[0mneed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrecurse\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mall\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1868 1695    0    0    0    0]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0][:6])\n",
    "print(dataset[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.502\n",
      "[1,  4000] loss: 0.503\n",
      "[1,  6000] loss: 0.500\n",
      "[1,  8000] loss: 0.501\n",
      "[1, 10000] loss: 0.503\n",
      "[2,  2000] loss: 0.497\n",
      "[2,  4000] loss: 0.498\n",
      "[2,  6000] loss: 0.495\n",
      "[2,  8000] loss: 0.492\n",
      "[2, 10000] loss: 0.494\n",
      "[3,  2000] loss: 0.489\n",
      "[3,  4000] loss: 0.489\n",
      "[3,  6000] loss: 0.486\n",
      "[3,  8000] loss: 0.483\n",
      "[3, 10000] loss: 0.485\n",
      "[4,  2000] loss: 0.482\n",
      "[4,  4000] loss: 0.483\n",
      "[4,  6000] loss: 0.478\n",
      "[4,  8000] loss: 0.471\n",
      "[4, 10000] loss: 0.474\n",
      "[5,  2000] loss: 0.471\n",
      "[5,  4000] loss: 0.475\n",
      "[5,  6000] loss: 0.470\n",
      "[5,  8000] loss: 0.459\n",
      "[5, 10000] loss: 0.463\n",
      "[6,  2000] loss: 0.463\n",
      "[6,  4000] loss: 0.467\n",
      "[6,  6000] loss: 0.463\n",
      "[6,  8000] loss: 0.457\n",
      "[6, 10000] loss: 0.454\n",
      "[7,  2000] loss: 0.456\n",
      "[7,  4000] loss: 0.461\n",
      "[7,  6000] loss: 0.453\n",
      "[7,  8000] loss: 0.439\n",
      "[7, 10000] loss: 0.443\n",
      "[8,  2000] loss: 0.445\n",
      "[8,  4000] loss: 0.451\n",
      "[8,  6000] loss: 0.445\n",
      "[8,  8000] loss: 0.431\n",
      "[8, 10000] loss: 0.433\n",
      "[9,  2000] loss: 0.437\n",
      "[9,  4000] loss: 0.445\n",
      "[9,  6000] loss: 0.439\n",
      "[9,  8000] loss: 0.425\n",
      "[9, 10000] loss: 0.427\n",
      "[10,  2000] loss: 0.434\n",
      "[10,  4000] loss: 0.437\n",
      "[10,  6000] loss: 0.435\n",
      "[10,  8000] loss: 0.419\n",
      "[10, 10000] loss: 0.425\n",
      "[11,  2000] loss: 0.436\n",
      "[11,  4000] loss: 0.436\n",
      "[11,  6000] loss: 0.431\n",
      "[11,  8000] loss: 0.417\n",
      "[11, 10000] loss: 0.420\n",
      "[12,  2000] loss: 0.426\n",
      "[12,  4000] loss: 0.427\n",
      "[12,  6000] loss: 0.430\n",
      "[12,  8000] loss: 0.412\n",
      "[12, 10000] loss: 0.418\n",
      "[13,  2000] loss: 0.426\n",
      "[13,  4000] loss: 0.427\n",
      "[13,  6000] loss: 0.423\n",
      "[13,  8000] loss: 0.404\n",
      "[13, 10000] loss: 0.412\n",
      "[14,  2000] loss: 0.425\n",
      "[14,  4000] loss: 0.432\n",
      "[14,  6000] loss: 0.431\n",
      "[14,  8000] loss: 0.417\n",
      "[14, 10000] loss: 0.415\n",
      "[15,  2000] loss: 0.427\n",
      "[15,  4000] loss: 0.427\n",
      "[15,  6000] loss: 0.432\n",
      "[15,  8000] loss: 0.416\n",
      "[15, 10000] loss: 0.416\n",
      "[16,  2000] loss: 0.423\n",
      "[16,  4000] loss: 0.430\n",
      "[16,  6000] loss: 0.425\n",
      "[16,  8000] loss: 0.406\n",
      "[16, 10000] loss: 0.413\n",
      "[17,  2000] loss: 0.422\n",
      "[17,  4000] loss: 0.430\n",
      "[17,  6000] loss: 0.427\n",
      "[17,  8000] loss: 0.414\n",
      "[17, 10000] loss: 0.418\n",
      "[18,  2000] loss: 0.428\n",
      "[18,  4000] loss: 0.434\n",
      "[18,  6000] loss: 0.430\n",
      "[18,  8000] loss: 0.410\n",
      "[18, 10000] loss: 0.412\n",
      "[19,  2000] loss: 0.424\n",
      "[19,  4000] loss: 0.432\n",
      "[19,  6000] loss: 0.429\n",
      "[19,  8000] loss: 0.405\n",
      "[19, 10000] loss: 0.413\n",
      "[20,  2000] loss: 0.422\n",
      "[20,  4000] loss: 0.433\n",
      "[20,  6000] loss: 0.427\n",
      "[20,  8000] loss: 0.405\n",
      "[20, 10000] loss: 0.410\n",
      "[21,  2000] loss: 0.421\n",
      "[21,  4000] loss: 0.425\n",
      "[21,  6000] loss: 0.427\n",
      "[21,  8000] loss: 0.410\n",
      "[21, 10000] loss: 0.411\n",
      "[22,  2000] loss: 0.422\n",
      "[22,  4000] loss: 0.428\n",
      "[22,  6000] loss: 0.421\n",
      "[22,  8000] loss: 0.403\n",
      "[22, 10000] loss: 0.409\n",
      "[23,  2000] loss: 0.425\n",
      "[23,  4000] loss: 0.432\n",
      "[23,  6000] loss: 0.429\n",
      "[23,  8000] loss: 0.405\n",
      "[23, 10000] loss: 0.410\n",
      "[24,  2000] loss: 0.420\n",
      "[24,  4000] loss: 0.422\n",
      "[24,  6000] loss: 0.424\n",
      "[24,  8000] loss: 0.410\n",
      "[24, 10000] loss: 0.411\n",
      "[25,  2000] loss: 0.422\n",
      "[25,  4000] loss: 0.428\n",
      "[25,  6000] loss: 0.429\n",
      "[25,  8000] loss: 0.410\n",
      "[25, 10000] loss: 0.413\n",
      "[26,  2000] loss: 0.428\n",
      "[26,  4000] loss: 0.429\n",
      "[26,  6000] loss: 0.427\n",
      "[26,  8000] loss: 0.411\n",
      "[26, 10000] loss: 0.409\n",
      "[27,  2000] loss: 0.422\n",
      "[27,  4000] loss: 0.427\n",
      "[27,  6000] loss: 0.428\n",
      "[27,  8000] loss: 0.403\n",
      "[27, 10000] loss: 0.409\n",
      "[28,  2000] loss: 0.420\n",
      "[28,  4000] loss: 0.424\n",
      "[28,  6000] loss: 0.421\n",
      "[28,  8000] loss: 0.404\n",
      "[28, 10000] loss: 0.409\n",
      "[29,  2000] loss: 0.420\n",
      "[29,  4000] loss: 0.422\n",
      "[29,  6000] loss: 0.425\n",
      "[29,  8000] loss: 0.408\n",
      "[29, 10000] loss: 0.410\n",
      "[30,  2000] loss: 0.420\n",
      "[30,  4000] loss: 0.431\n",
      "[30,  6000] loss: 0.431\n",
      "[30,  8000] loss: 0.403\n",
      "[30, 10000] loss: 0.410\n",
      "[31,  2000] loss: 0.423\n",
      "[31,  4000] loss: 0.428\n",
      "[31,  6000] loss: 0.428\n",
      "[31,  8000] loss: 0.400\n",
      "[31, 10000] loss: 0.414\n",
      "[32,  2000] loss: 0.424\n",
      "[32,  4000] loss: 0.430\n",
      "[32,  6000] loss: 0.426\n",
      "[32,  8000] loss: 0.408\n",
      "[32, 10000] loss: 0.409\n",
      "[33,  2000] loss: 0.419\n",
      "[33,  4000] loss: 0.428\n",
      "[33,  6000] loss: 0.423\n",
      "[33,  8000] loss: 0.404\n",
      "[33, 10000] loss: 0.413\n",
      "[34,  2000] loss: 0.423\n",
      "[34,  4000] loss: 0.429\n",
      "[34,  6000] loss: 0.425\n",
      "[34,  8000] loss: 0.404\n",
      "[34, 10000] loss: 0.411\n",
      "[35,  2000] loss: 0.421\n",
      "[35,  4000] loss: 0.426\n",
      "[35,  6000] loss: 0.426\n",
      "[35,  8000] loss: 0.409\n",
      "[35, 10000] loss: 0.413\n",
      "[36,  2000] loss: 0.428\n",
      "[36,  4000] loss: 0.430\n",
      "[36,  6000] loss: 0.432\n",
      "[36,  8000] loss: 0.412\n",
      "[36, 10000] loss: 0.414\n",
      "[37,  2000] loss: 0.425\n",
      "[37,  4000] loss: 0.431\n",
      "[37,  6000] loss: 0.424\n",
      "[37,  8000] loss: 0.406\n",
      "[37, 10000] loss: 0.410\n",
      "[38,  2000] loss: 0.422\n",
      "[38,  4000] loss: 0.426\n",
      "[38,  6000] loss: 0.425\n",
      "[38,  8000] loss: 0.399\n",
      "[38, 10000] loss: 0.408\n",
      "[39,  2000] loss: 0.421\n",
      "[39,  4000] loss: 0.434\n",
      "[39,  6000] loss: 0.422\n",
      "[39,  8000] loss: 0.404\n",
      "[39, 10000] loss: 0.410\n",
      "[40,  2000] loss: 0.420\n",
      "[40,  4000] loss: 0.421\n",
      "[40,  6000] loss: 0.423\n",
      "[40,  8000] loss: 0.400\n",
      "[40, 10000] loss: 0.403\n",
      "[41,  2000] loss: 0.418\n",
      "[41,  4000] loss: 0.428\n",
      "[41,  6000] loss: 0.425\n",
      "[41,  8000] loss: 0.406\n",
      "[41, 10000] loss: 0.410\n",
      "[42,  2000] loss: 0.422\n",
      "[42,  4000] loss: 0.425\n",
      "[42,  6000] loss: 0.424\n",
      "[42,  8000] loss: 0.405\n",
      "[42, 10000] loss: 0.409\n",
      "[43,  2000] loss: 0.425\n",
      "[43,  4000] loss: 0.430\n",
      "[43,  6000] loss: 0.431\n",
      "[43,  8000] loss: 0.413\n",
      "[43, 10000] loss: 0.413\n",
      "[44,  2000] loss: 0.424\n",
      "[44,  4000] loss: 0.429\n",
      "[44,  6000] loss: 0.424\n",
      "[44,  8000] loss: 0.412\n",
      "[44, 10000] loss: 0.417\n",
      "[45,  2000] loss: 0.429\n",
      "[45,  4000] loss: 0.429\n",
      "[45,  6000] loss: 0.429\n",
      "[45,  8000] loss: 0.410\n",
      "[45, 10000] loss: 0.416\n",
      "[46,  2000] loss: 0.428\n",
      "[46,  4000] loss: 0.431\n",
      "[46,  6000] loss: 0.426\n",
      "[46,  8000] loss: 0.410\n",
      "[46, 10000] loss: 0.411\n",
      "[47,  2000] loss: 0.424\n",
      "[47,  4000] loss: 0.430\n",
      "[47,  6000] loss: 0.424\n",
      "[47,  8000] loss: 0.411\n",
      "[47, 10000] loss: 0.414\n",
      "[48,  2000] loss: 0.423\n",
      "[48,  4000] loss: 0.428\n",
      "[48,  6000] loss: 0.425\n",
      "[48,  8000] loss: 0.407\n",
      "[48, 10000] loss: 0.408\n",
      "[49,  2000] loss: 0.417\n",
      "[49,  4000] loss: 0.427\n",
      "[49,  6000] loss: 0.421\n",
      "[49,  8000] loss: 0.398\n",
      "[49, 10000] loss: 0.409\n",
      "[50,  2000] loss: 0.419\n",
      "[50,  4000] loss: 0.432\n",
      "[50,  6000] loss: 0.430\n",
      "[50,  8000] loss: 0.413\n",
      "[50, 10000] loss: 0.412\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "PATH = './prob_net63.pth'\n",
    "net = Net()\n",
    "#net.load_state_dict(torch.load(PATH))\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "#optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "random.shuffle(dataset)\n",
    "dataset = dataset[:10000]\n",
    "for dsCounter in range(50):\n",
    "    c = 0\n",
    "    running_loss = 0.0\n",
    "    for data in dataset:\n",
    "        c = c + 1\n",
    "        input = torch.tensor(data[:6], dtype = torch.float, requires_grad=True)\n",
    "        target = torch.tensor(data[-1], dtype=torch.float, requires_grad=True)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = net(input)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if c % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (dsCounter + 1, c + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
